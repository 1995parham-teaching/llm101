---
theme: seriph
title: LLM 101
info: |
  ## LLM 101

  Presentation about Large Language Models from a non-AI developer
class: text-center
drawings:
  persist: false
mdc: true
overviewSnapshots: true
favicon: "https://github.com/1995parham-me.png"
hideInToc: true
---

## LLM 101

Presentation about **Large Language Models** from a non-AI developer

<div class="abs-br m-6 flex">
  <a href="https://github.com/1995parham-teaching/llm101" target="_blank" alt="GitHub" title="Open in GitHub"
    class="text-xl slidev-icon-btn opacity-50 !border-none !hover:text-white">
    <carbon-logo-github />
  </a>
</div>

---

<Toc />

---

# Introduction

An LLM is a neural network designed to understand, generate, and respond to human-like text. These models are deep
neural networks trained on massive amounts of text data, sometimes encompassing large portions of the entire publicly
available text on the internet.

The **large** in **large language model** refers to both the model's size in terms of parameters and the immense dataset
on which it's trained.
